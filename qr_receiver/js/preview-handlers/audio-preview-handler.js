/**
 * @fileoverview Audio Preview Handler - Focused Audio File Processing
 * 
 * ROOT CAUSE SOLUTION: Extracted from monolithic FilePreviewSystem into focused
 * handler with waveform visualization, metadata extraction, and audio-specific features.
 * 
 * Supports all audio formats with proper audio controls, waveform display,
 * and metadata extraction (duration, bitrate, sample rate, etc.).
 */

/**
 * Audio Preview Handler
 * Handles all audio file types with waveform visualization and advanced controls
 * 
 * @class AudioPreviewHandler
 * @extends {BasePreviewHandler}
 */
class AudioPreviewHandler extends BasePreviewHandler {
    constructor() {
        super();
        
        /** @type {Map<string, HTMLAudioElement>} Cache for loaded audio */
        this.audioCache = new Map();
        
        /** @type {number} Maximum cache size - configurable */
        this.maxCacheSize = window.AppConfig?.get('performance.tier') === 'high' ? 10 : 
                          window.AppConfig?.get('performance.tier') === 'medium' ? 5 : 3;
        
        /** @type {AudioContext} Web Audio API context */
        this.audioContext = null;
        
        /** @type {Object} Current audio analysis */
        this.currentAnalysis = null;
    }
    
    /**
     * Get handler capabilities
     * @returns {PreviewHandlerCapabilities} Handler capabilities
     */
    getCapabilities() {
        return {
            mimeTypes: [
                'audio/mpeg',
                'audio/mp3',
                'audio/wav',
                'audio/wave',
                'audio/x-wav',
                'audio/ogg',
                'audio/webm',
                'audio/mp4',
                'audio/m4a',
                'audio/aac',
                'audio/flac',
                'audio/x-flac'
            ],
            extensions: [
                'mp3', 'wav', 'ogg', 'webm', 'm4a', 'aac', 'flac', 'wma', 'opus'
            ],
            maxFileSize: window.AppConfig?.get('filePreview.maxPreviewSizes.audio') || 100 * 1024 * 1024,
            supportsStreaming: true,
            supportsAsync: true,
            features: ['waveform', 'metadata', 'duration', 'audio-analysis', 'playback-controls']
        };
    }
    
    /**
     * Generate audio preview
     * @param {PreviewContext} context - Preview context
     * @returns {Promise<PreviewResult>} Preview result
     */
    async generatePreview(context) {
        const { data, mimeType, filename, container, onProgress } = context;
        
        // Create loading indicator
        const loadingElement = this.createLoadingElement('Loading audio file...');
        container.appendChild(loadingElement);
        
        if (onProgress) onProgress(0.1, 'Creating audio blob...');
        
        // Create blob and object URL
        const blob = new Blob([data], { type: mimeType });
        const audioUrl = this.createObjectURL(blob);
        
        if (onProgress) onProgress(0.3, 'Loading audio data...');
        
        // Create and configure audio element
        const audio = await this.createAudioElement(audioUrl, filename);
        
        if (onProgress) onProgress(0.6, 'Analyzing audio properties...');
        
        // Analyze audio
        const analysis = await this.analyzeAudio(audio, data, mimeType);
        
        if (onProgress) onProgress(0.8, 'Creating audio visualization...');
        
        // Create audio container with controls and visualization
        const audioContainer = await this.createAudioContainer(audio, analysis, context);
        
        // Replace loading with actual content
        container.removeChild(loadingElement);
        container.appendChild(audioContainer);
        
        if (onProgress) onProgress(1.0, 'Audio preview ready');
        
        // Extract metadata
        const metadata = await this.extractAudioMetadata(audio, analysis, data, mimeType);
        
        return {
            element: audioContainer,
            metadata: metadata,
            cleanup: [
                () => this.revokeObjectURL(audioUrl),
                () => this.removeFromCache(filename),
                () => this.pauseAudio(audio)
            ],
            resources: {
                audioUrl: audioUrl,
                audioElement: audio,
                analysis: analysis
            }
        };
    }
    
    /**
     * Create audio element with error handling
     * @param {string} audioUrl - Audio object URL
     * @param {string} filename - Original filename
     * @returns {Promise<HTMLAudioElement>} Loaded audio element
     */
    async createAudioElement(audioUrl, filename) {
        return new Promise((resolve, reject) => {
            const audio = new Audio();
            
            // Set up loading handlers
            audio.onloadedmetadata = () => {
                console.log(`üéµ Audio loaded: ${filename} (${this.formatDuration(audio.duration)})`);
                
                // Cache audio if reasonable size
                if (this.shouldCacheAudio(audio)) {
                    this.addToCache(filename, audio);
                }
                
                resolve(audio);
            };
            
            audio.onerror = (error) => {
                console.error(`‚ùå Audio load failed: ${filename}`, error);
                reject(new Error(`Failed to load audio: ${filename}`));
            };
            
            // Configure audio
            audio.preload = 'metadata';
            audio.controls = false; // We'll create custom controls
            
            // Start loading
            audio.src = audioUrl;
        });
    }
    
    /**
     * Analyze audio properties
     * @param {HTMLAudioElement} audio - Audio element
     * @param {Uint8Array} data - Audio data
     * @param {string} mimeType - MIME type
     * @returns {Promise<Object>} Audio analysis
     */
    async analyzeAudio(audio, data, mimeType) {
        const analysis = {
            duration: audio.duration || 0,
            fileSize: data.length,
            mimeType: mimeType,
            format: this.getAudioFormat(mimeType),
            estimatedBitrate: 0,
            estimatedSampleRate: 44100, // Default assumption
            channels: 2, // Default assumption
            quality: 'unknown'
        };
        
        // Estimate bitrate from file size and duration
        if (analysis.duration > 0) {
            // Bitrate = (file size in bits) / duration in seconds
            analysis.estimatedBitrate = Math.round((data.length * 8) / analysis.duration / 1000); // kbps
            
            // Estimate quality based on bitrate
            analysis.quality = this.estimateAudioQuality(analysis.estimatedBitrate);
        }
        
        // Try to get more accurate audio properties using Web Audio API
        try {
            const webAudioAnalysis = await this.analyzeWithWebAudio(data);
            Object.assign(analysis, webAudioAnalysis);
        } catch (error) {
            console.log('Web Audio analysis not available:', error);
        }
        
        return analysis;
    }
    
    /**
     * Analyze audio using Web Audio API
     * @param {Uint8Array} data - Audio data
     * @returns {Promise<Object>} Web Audio analysis
     */
    async analyzeWithWebAudio(data) {
        try {
            // Initialize Audio Context if needed
            if (!this.audioContext) {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            // Decode audio data
            const arrayBuffer = data.buffer.slice(data.byteOffset, data.byteOffset + data.byteLength);
            const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
            
            return {
                actualSampleRate: audioBuffer.sampleRate,
                actualChannels: audioBuffer.numberOfChannels,
                actualDuration: audioBuffer.duration,
                bufferLength: audioBuffer.length
            };
        } catch (error) {
            console.warn('Web Audio analysis failed:', error);
            return {};
        }
    }
    
    /**
     * Get audio format from MIME type
     * @param {string} mimeType - MIME type
     * @returns {string} Audio format
     */
    getAudioFormat(mimeType) {
        const formatMap = {
            'audio/mpeg': 'MP3',
            'audio/mp3': 'MP3',
            'audio/wav': 'WAV',
            'audio/wave': 'WAV',
            'audio/x-wav': 'WAV',
            'audio/ogg': 'OGG',
            'audio/webm': 'WebM',
            'audio/mp4': 'MP4',
            'audio/m4a': 'M4A',
            'audio/aac': 'AAC',
            'audio/flac': 'FLAC',
            'audio/x-flac': 'FLAC'
        };
        
        return formatMap[mimeType] || 'Unknown';
    }
    
    /**
     * Estimate audio quality from bitrate
     * @param {number} bitrate - Bitrate in kbps
     * @returns {string} Quality description
     */
    estimateAudioQuality(bitrate) {
        if (bitrate >= 320) return 'Very High (‚â•320 kbps)';
        if (bitrate >= 256) return 'High (256-319 kbps)';
        if (bitrate >= 192) return 'Good (192-255 kbps)';
        if (bitrate >= 128) return 'Standard (128-191 kbps)';
        if (bitrate >= 96) return 'Low (96-127 kbps)';
        return 'Very Low (<96 kbps)';
    }
    
    /**
     * Create audio container with controls and visualization
     * @param {HTMLAudioElement} audio - Audio element
     * @param {Object} analysis - Audio analysis
     * @param {PreviewContext} context - Preview context
     * @returns {Promise<HTMLElement>} Audio container
     */
    async createAudioContainer(audio, analysis, context) {
        const container = this.createContainer('audio-preview-container');
        
        // Create audio info header
        const infoHeader = this.createAudioInfoHeader(analysis, context);
        container.appendChild(infoHeader);
        
        // Create waveform visualization (simplified)
        const waveform = await this.createWaveformVisualization(audio, analysis);
        container.appendChild(waveform);
        
        // Create custom audio controls
        const controls = this.createAudioControls(audio, analysis);
        container.appendChild(controls);
        
        // Create audio metadata display
        const metadata = this.createAudioMetadataDisplay(analysis);
        container.appendChild(metadata);
        
        // Store analysis for controls
        this.currentAnalysis = analysis;
        
        return container;
    }
    
    /**
     * Create audio info header
     * @param {Object} analysis - Audio analysis
     * @param {PreviewContext} context - Preview context
     * @returns {HTMLElement} Info header
     */
    createAudioInfoHeader(analysis, context) {
        const header = document.createElement('div');
        header.className = 'audio-info-header';
        
        const duration = this.formatDuration(analysis.duration);
        const fileSize = this.formatBytes(analysis.fileSize);
        const channels = analysis.actualChannels || analysis.channels;
        const channelText = channels === 1 ? 'Mono' : channels === 2 ? 'Stereo' : `${channels} Channels`;
        
        header.innerHTML = `
            <div class="audio-icon">üéµ</div>
            <div class="audio-basic-info">
                <div class="audio-title">${this.escapeHtml(context.filename)}</div>
                <div class="audio-stats">
                    <span class="stat-item">‚è±Ô∏è ${duration}</span>
                    <span class="stat-item">üìä ${fileSize}</span>
                    <span class="stat-item">üéØ ${analysis.format}</span>
                    <span class="stat-item">üì° ${channelText}</span>
                    <span class="stat-item">‚ö° ${analysis.estimatedBitrate} kbps</span>
                </div>
            </div>
        `;
        
        return header;
    }
    
    /**
     * Create waveform visualization
     * @param {HTMLAudioElement} audio - Audio element
     * @param {Object} analysis - Audio analysis
     * @returns {Promise<HTMLElement>} Waveform element
     */
    async createWaveformVisualization(audio, analysis) {
        const waveformContainer = document.createElement('div');
        waveformContainer.className = 'audio-waveform-container';
        
        // Create simplified waveform visualization
        const waveform = document.createElement('div');
        waveform.className = 'audio-waveform';
        
        // Generate mock waveform bars (in production, would use actual audio analysis)
        const bars = 100;
        for (let i = 0; i < bars; i++) {
            const bar = document.createElement('div');
            bar.className = 'waveform-bar';
            
            // Create pseudo-random heights based on position
            const height = Math.sin(i * 0.1) * 0.5 + 0.3 + Math.random() * 0.2;
            bar.style.height = `${height * 100}%`;
            
            waveform.appendChild(bar);
        }
        
        // Create progress indicator
        const progressIndicator = document.createElement('div');
        progressIndicator.className = 'waveform-progress';
        
        waveformContainer.appendChild(waveform);
        waveformContainer.appendChild(progressIndicator);
        
        // Bind waveform click for seeking
        this.bindWaveformEvents(waveformContainer, audio);
        
        return waveformContainer;
    }
    
    /**
     * Create custom audio controls
     * @param {HTMLAudioElement} audio - Audio element
     * @param {Object} analysis - Audio analysis
     * @returns {HTMLElement} Controls container
     */
    createAudioControls(audio, analysis) {
        const controls = document.createElement('div');
        controls.className = 'audio-controls';
        
        controls.innerHTML = `
            <div class="playback-controls">
                <button class="control-btn play-pause-btn" data-playing="false" title="Play/Pause">‚ñ∂Ô∏è</button>
                <button class="control-btn stop-btn" title="Stop">‚èπÔ∏è</button>
                <button class="control-btn rewind-btn" title="Rewind 10s">‚è™</button>
                <button class="control-btn forward-btn" title="Forward 10s">‚è©</button>
            </div>
            <div class="time-display">
                <span class="current-time">0:00</span>
                <span class="time-separator">/</span>
                <span class="total-time">${this.formatDuration(analysis.duration)}</span>
            </div>
            <div class="volume-controls">
                <button class="control-btn mute-btn" title="Mute">üîä</button>
                <input type="range" class="volume-slider" min="0" max="100" value="100" title="Volume">
            </div>
            <div class="additional-controls">
                <button class="control-btn loop-btn" title="Loop">üîÑ</button>
                <button class="control-btn speed-btn" title="Playback Speed">1√ó</button>
                <button class="control-btn download-btn" title="Download Audio">‚¨áÔ∏è</button>
            </div>
        `;
        
        // Bind control events
        this.bindAudioControlEvents(controls, audio);
        
        return controls;
    }
    
    /**
     * Create audio metadata display
     * @param {Object} analysis - Audio analysis
     * @returns {HTMLElement} Metadata display
     */
    createAudioMetadataDisplay(analysis) {
        const metadata = document.createElement('div');
        metadata.className = 'audio-metadata';
        
        metadata.innerHTML = `
            <div class="metadata-section">
                <h4>Audio Properties</h4>
                <div class="metadata-grid">
                    <div class="metadata-item">
                        <span class="metadata-label">Format:</span>
                        <span class="metadata-value">${analysis.format}</span>
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Duration:</span>
                        <span class="metadata-value">${this.formatDuration(analysis.duration)}</span>
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Bitrate:</span>
                        <span class="metadata-value">${analysis.estimatedBitrate} kbps</span>
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Sample Rate:</span>
                        <span class="metadata-value">${analysis.actualSampleRate || analysis.estimatedSampleRate} Hz</span>
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Channels:</span>
                        <span class="metadata-value">${analysis.actualChannels || analysis.channels}</span>
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Quality:</span>
                        <span class="metadata-value">${analysis.quality}</span>
                    </div>
                </div>
            </div>
        `;
        
        return metadata;
    }
    
    /**
     * Bind waveform interaction events
     * @param {HTMLElement} waveformContainer - Waveform container
     * @param {HTMLAudioElement} audio - Audio element
     */
    bindWaveformEvents(waveformContainer, audio) {
        const waveform = waveformContainer.querySelector('.audio-waveform');
        const progressIndicator = waveformContainer.querySelector('.waveform-progress');
        
        // Click to seek
        waveform.addEventListener('click', (e) => {
            const rect = waveform.getBoundingClientRect();
            const clickX = e.clientX - rect.left;
            const percentage = clickX / rect.width;
            const newTime = percentage * audio.duration;
            
            audio.currentTime = newTime;
            this.updateWaveformProgress(progressIndicator, percentage);
        });
        
        // Update progress during playback
        audio.addEventListener('timeupdate', () => {
            if (audio.duration > 0) {
                const percentage = audio.currentTime / audio.duration;
                this.updateWaveformProgress(progressIndicator, percentage);
            }
        });
    }
    
    /**
     * Update waveform progress indicator
     * @param {HTMLElement} progressIndicator - Progress indicator element
     * @param {number} percentage - Progress percentage (0-1)
     */
    updateWaveformProgress(progressIndicator, percentage) {
        progressIndicator.style.width = `${percentage * 100}%`;
    }
    
    /**
     * Bind audio control events
     * @param {HTMLElement} controls - Controls container
     * @param {HTMLAudioElement} audio - Audio element
     */
    bindAudioControlEvents(controls, audio) {
        const playPauseBtn = controls.querySelector('.play-pause-btn');
        const stopBtn = controls.querySelector('.stop-btn');
        const rewindBtn = controls.querySelector('.rewind-btn');
        const forwardBtn = controls.querySelector('.forward-btn');
        const muteBtn = controls.querySelector('.mute-btn');
        const volumeSlider = controls.querySelector('.volume-slider');
        const loopBtn = controls.querySelector('.loop-btn');
        const speedBtn = controls.querySelector('.speed-btn');
        const downloadBtn = controls.querySelector('.download-btn');
        const currentTimeDisplay = controls.querySelector('.current-time');
        
        let playbackSpeeds = [0.5, 0.75, 1, 1.25, 1.5, 2];
        let currentSpeedIndex = 2; // 1x speed
        
        // Play/Pause
        playPauseBtn.addEventListener('click', () => {
            if (audio.paused) {
                audio.play();
                playPauseBtn.textContent = '‚è∏Ô∏è';
                playPauseBtn.setAttribute('data-playing', 'true');
            } else {
                audio.pause();
                playPauseBtn.textContent = '‚ñ∂Ô∏è';
                playPauseBtn.setAttribute('data-playing', 'false');
            }
        });
        
        // Stop
        stopBtn.addEventListener('click', () => {
            audio.pause();
            audio.currentTime = 0;
            playPauseBtn.textContent = '‚ñ∂Ô∏è';
            playPauseBtn.setAttribute('data-playing', 'false');
        });
        
        // Rewind
        rewindBtn.addEventListener('click', () => {
            audio.currentTime = Math.max(0, audio.currentTime - 10);
        });
        
        // Forward
        forwardBtn.addEventListener('click', () => {
            audio.currentTime = Math.min(audio.duration, audio.currentTime + 10);
        });
        
        // Mute/Unmute
        muteBtn.addEventListener('click', () => {
            audio.muted = !audio.muted;
            muteBtn.textContent = audio.muted ? 'üîá' : 'üîä';
        });
        
        // Volume
        volumeSlider.addEventListener('input', () => {
            audio.volume = volumeSlider.value / 100;
        });
        
        // Loop
        loopBtn.addEventListener('click', () => {
            audio.loop = !audio.loop;
            loopBtn.style.opacity = audio.loop ? '1' : '0.5';
        });
        
        // Speed
        speedBtn.addEventListener('click', () => {
            currentSpeedIndex = (currentSpeedIndex + 1) % playbackSpeeds.length;
            const speed = playbackSpeeds[currentSpeedIndex];
            audio.playbackRate = speed;
            speedBtn.textContent = `${speed}√ó`;
        });
        
        // Download
        downloadBtn.addEventListener('click', () => {
            this.downloadCurrentAudio(audio);
        });
        
        // Time update
        audio.addEventListener('timeupdate', () => {
            currentTimeDisplay.textContent = this.formatDuration(audio.currentTime);
        });
    }
    
    /**
     * Format duration in MM:SS format
     * @param {number} seconds - Duration in seconds
     * @returns {string} Formatted duration
     */
    formatDuration(seconds) {
        if (!seconds || isNaN(seconds)) return '0:00';
        
        const minutes = Math.floor(seconds / 60);
        const remainingSeconds = Math.floor(seconds % 60);
        return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
    }
    
    /**
     * Download current audio file
     * @param {HTMLAudioElement} audio - Audio element
     */
    downloadCurrentAudio(audio) {
        try {
            const link = document.createElement('a');
            link.href = audio.src;
            link.download = 'audio_file';
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
        } catch (error) {
            console.error('Audio download failed:', error);
        }
    }
    
    /**
     * Extract audio metadata
     * @param {HTMLAudioElement} audio - Audio element
     * @param {Object} analysis - Audio analysis
     * @param {Uint8Array} data - Audio data
     * @param {string} mimeType - MIME type
     * @returns {Promise<Object>} Audio metadata
     */
    async extractAudioMetadata(audio, analysis, data, mimeType) {
        const metadata = await super.extractMetadata({
            filename: 'audio_file',
            mimeType: mimeType,
            fileSize: data.length
        });
        
        // Add audio-specific metadata
        metadata.duration = analysis.duration;
        metadata.format = analysis.format;
        metadata.bitrate = analysis.estimatedBitrate;
        metadata.sampleRate = analysis.actualSampleRate || analysis.estimatedSampleRate;
        metadata.channels = analysis.actualChannels || analysis.channels;
        metadata.quality = analysis.quality;
        
        return metadata;
    }
    
    /**
     * Pause audio playback
     * @param {HTMLAudioElement} audio - Audio element
     */
    pauseAudio(audio) {
        if (audio && !audio.paused) {
            audio.pause();
        }
    }
    
    /**
     * Check if audio should be cached
     * @param {HTMLAudioElement} audio - Audio element
     * @returns {boolean} Whether to cache audio
     */
    shouldCacheAudio(audio) {
        // Cache short audio files only
        return audio.duration < 60; // Under 1 minute
    }
    
    /**
     * Add audio to cache
     * @param {string} filename - Cache key
     * @param {HTMLAudioElement} audio - Audio to cache
     */
    addToCache(filename, audio) {
        // Remove oldest if cache is full
        if (this.audioCache.size >= this.maxCacheSize) {
            const firstKey = this.audioCache.keys().next().value;
            this.audioCache.delete(firstKey);
        }
        
        this.audioCache.set(filename, audio.cloneNode());
    }
    
    /**
     * Remove audio from cache
     * @param {string} filename - Cache key
     */
    removeFromCache(filename) {
        this.audioCache.delete(filename);
    }
    
    /**
     * Clean up handler resources
     */
    cleanup() {
        super.cleanup();
        
        // Close audio context if created
        if (this.audioContext && this.audioContext.state !== 'closed') {
            this.audioContext.close();
            this.audioContext = null;
        }
        
        // Clear audio cache
        this.audioCache.clear();
        
        // Clear current analysis
        this.currentAnalysis = null;
        
        console.log('üßπ Audio handler cleanup complete');
    }
}

// Export for ES6 modules
export { AudioPreviewHandler };